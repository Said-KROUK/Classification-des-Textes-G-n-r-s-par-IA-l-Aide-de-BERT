{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_nlp keras_core"
      ],
      "metadata": {
        "id": "A3JuoGiUElg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import keras_core as keras\n",
        "import keras_nlp\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "print(\"KerasNLP version:\", keras_nlp.__version__)"
      ],
      "metadata": {
        "id": "NYIuRUbKEdF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path_daigt_v4_train_dataset = kagglehub.dataset_download(\"thedrcat/daigt-v4-train-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path_daigt_v4_train_dataset)"
      ],
      "metadata": {
        "id": "j3TK_sJomaPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daigt_v4_train_datase = pd.read_csv(path_daigt_v4_train_dataset+'/train_v4_drcat_01.csv')\n",
        "daigt_v4_train_datase.head()"
      ],
      "metadata": {
        "id": "_dz7LnhrAIt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fonction pour afficher un graphique en camembert pour chaque dataset\n",
        "def plot_pie_chart(ax, train_data, label, title):\n",
        "    label_counts = train_data[label].value_counts()\n",
        "    label_counts.plot.pie(autopct='%1.1f%%', startangle=90, cmap='Set3', ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel('')  # Supprimer le label de l'axe y\n",
        "\n",
        "# Cr√©er un tableau de graphiques 2x2\n",
        "fig, axs = plt.subplots(3, 2, figsize=(16, 12))\n",
        "\n",
        "# Afficher les graphiques en camembert pour chaque dataset\n",
        "plot_pie_chart(axs[0,0], daigt_v4_train_datase,'label', 'Distribution des valeurs dans la colonne '+ 'generated')\n",
        "plot_pie_chart(axs[0,1], daigt_v4_train_datase,'RDizzl3_seven', 'Distribution des valeurs dans la colonne generated')\n",
        "plot_pie_chart(axs[1,0], daigt_v4_train_datase,'model', 'Distribution des valeurs dans la colonne model')\n",
        "plot_pie_chart(axs[1,1], daigt_v4_train_datase,'source', 'Distribution des valeurs dans la colonne source')\n",
        "plot_pie_chart(axs[2,0], daigt_v4_train_datase,'prompt_name', 'Distribution des valeurs dans la colonne prompt_name')\n",
        "# Ajuster les espaces entre les graphiques\n",
        "plt.tight_layout()\n",
        "\n",
        "# Afficher les graphiques\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "94W801hkAW83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: caculer les valeur unique dans colone source et model\n",
        "\n",
        "print(\"Unique values in 'source' column:\", daigt_v4_train_datase['source'].unique())\n",
        "print(\"\\nUnique values in 'model' column:\", daigt_v4_train_datase['model'].unique())\n",
        "print(\" nbr Unique values in 'source' column:\", len(daigt_v4_train_datase['source'].unique()))\n",
        "print(\"\\n nbr Unique values in 'model' column:\", len(daigt_v4_train_datase['model'].unique()))"
      ],
      "metadata": {
        "id": "D2YGgQ_NBoB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daigt_v4_train_datase.rename(columns = {\"label\":\"generated\"}, inplace=True)"
      ],
      "metadata": {
        "id": "RyA5O9a5RM0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daigt_v4_train_datase.head()"
      ],
      "metadata": {
        "id": "ie44AVLPRXms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/llm_dataset/train_essays.csv')\n",
        "train.head()"
      ],
      "metadata": {
        "id": "9TE93auNMbca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_essays_final = pd.concat([train[[\"text\", \"generated\"]], daigt_v4_train_datase[[\"text\", \"generated\"]]])\n",
        "\n",
        "df_train_essays_final.info()"
      ],
      "metadata": {
        "id": "sGICA5SwMZaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We choose 512 because it's the limit of DistilBert\n",
        "SEQ_LENGTH = 512\n",
        "\n",
        "# Use a shorter sequence length.\n",
        "preprocessor = keras_nlp.models.DistilBertPreprocessor.from_preset(\n",
        "    \"distil_bert_base_en_uncased\",\n",
        "    sequence_length=SEQ_LENGTH,\n",
        ")\n",
        "\n",
        "# Pretrained classifier.\n",
        "classifier = keras_nlp.models.DistilBertClassifier.from_preset(\n",
        "    \"distil_bert_base_en_uncased\",\n",
        "    num_classes=2,\n",
        "    activation=None,\n",
        "    preprocessor=preprocessor,\n",
        ")\n",
        "\n",
        "# Re-compile (e.g., with a new learning rate)\n",
        "classifier.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\n",
        "        keras.metrics.SparseCategoricalAccuracy()\n",
        "   ]\n",
        ")\n",
        "\n",
        "\n",
        "# Access backbone programmatically (e.g., to change `trainable`).\n",
        "classifier.backbone.trainable = False\n",
        "\n",
        "\n",
        "classifier.summary()"
      ],
      "metadata": {
        "id": "RJRDs1cgAOhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train_essays_final[\"text\"],\n",
        "                                                    df_train_essays_final[\"generated\"],\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "id": "NNBpMlYDFLr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "classifier.fit(x=X_train,\n",
        "               y=y_train,\n",
        "               validation_data=(X_test, y_test),\n",
        "               epochs=10,\n",
        "               batch_size=64)"
      ],
      "metadata": {
        "id": "5K_O7h94GJPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mw3nUeDkeP61"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}